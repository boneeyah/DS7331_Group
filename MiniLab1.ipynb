{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c417ca4e-c052-44e2-9f4b-3e0c84e88cdc",
   "metadata": {},
   "source": [
    "#### data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9722752c-e0e1-4862-bece-058690ae9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "df = pd.read_csv(\"https://media.githubusercontent.com/media/boneeyah/DS7331_Group/main/Data_Files/airbnb_los_angeles.csv\")\n",
    "#df = pd.read_csv(\"Data_Files/airbnb_los_angeles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8676f5-9c08-472a-94b0-7cf8ac42ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop variables which won't be useful for the classification model\n",
    "for col in [\n",
    "    'listing_url','scrape_id','last_scraped','description','neighborhood_overview','picture_url','host_url','host_about','host_response_time','host_response_rate','host_acceptance_rate',\n",
    "    'host_thumbnail_url','host_picture_url','host_verifications','host_has_profile_pic','bathroom_text','host_listings_count','host_neighbourhood','bathrooms','minimum_minimum_nights',\n",
    "    'maximum_minimum_nights','minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm','maximum_nights_avg_ntm','calendar_updated','availability_30','availability_60',\n",
    "    'availability_90','availability_365','calendar_last_scraped','number_of_reviews_ltm','number_of_reviews_l30d','review_scores_accuracy','review_scores_communication','review_scores_cleanliness',\n",
    "    'review_scores_checkin','review_scores_value','review_scores_location','calculated_host_listings_count_entire_homes','calculated_host_listings_count_private_rooms',\n",
    "    'calculated_host_listings_count_shared_rooms','reviews_per_month','neighbourhood','neighbourhood_group_cleansed', 'first_review','last_review','minimum_nights','maximum_nights','license','name','host_name'\n",
    "]:\n",
    "    if col in df:\n",
    "        del df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84031bd0-0813-4264-81fa-f3548cb72b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nulls\n",
    "df = df[~df.review_scores_rating.isnull() & ~df.bathrooms_text.isnull() & ~df.host_since.isnull() & ~df.host_location.isnull()]\n",
    "\n",
    "## getting property type from string\n",
    "types = ['Private room', 'Entire', 'Room in hotel','Room','Shared room']\n",
    "pat = '|'.join(r\"\\b{}\\b\".format(x) for x in types)\n",
    "\n",
    "df['property_type']= df['property_type'].str.extract('('+ pat + ')', expand = False)\n",
    "df['property_type'] = (df.property_type.\n",
    "                       fillna(value = 'other').\n",
    "                       replace(['Entire','Room in hotel'],['Entire unit','Hotel room']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e58420e-ee3a-4444-a029-c8234aad0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute values based on median\n",
    "df['beds'] = df[['accommodates','beds']].groupby(by = 'accommodates').transform(lambda grp: grp.fillna(grp.median()))\n",
    "df_grouped = df.groupby(by = ['property_type','beds'])\n",
    "df_imputed = df_grouped[['beds','bedrooms']].transform(lambda grp: grp.fillna(grp.median()))\n",
    "\n",
    "index = df_imputed[df_imputed.bedrooms.isnull()].index\n",
    "df = df.drop(index= index)\n",
    "\n",
    "df['imputed']=df_imputed[['bedrooms']]\n",
    "\n",
    "# replace 'bedrooms' column with imputed column and deleting the duplicated column\n",
    "df['bedrooms'] = df['imputed']\n",
    "del df['imputed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63e7586-90a1-4694-aa9f-54a8bdf0c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now fixing dtypes for attributes\n",
    "df['host_since'] = pd.to_datetime(df.host_since)\n",
    "df['price'] = df['price'].replace('[\\$,]','',regex = True).astype(float)\n",
    "df['bathrooms_text'] = df['bathrooms_text'].replace(['Half-bath', 'Shared half-bath', 'Private half-bath'],['0.5 bath','0.5 shared bath', '0.5 private bath'])\n",
    "df_bathrooms = df['bathrooms_text'].str.split(n=1, expand=True).rename(columns = {0:'bathroom_number',1:'bathroom_type'})\n",
    "df_bathrooms['bathroom_type'] = df_bathrooms.bathroom_type.fillna(value = 'bath')\n",
    "df_bathrooms['bathroom_type'] = df_bathrooms['bathroom_type'].replace(['baths','shared baths'],['bath','shared bath'])\n",
    "df_bathrooms['bathroom_number'] = df_bathrooms['bathroom_number'].astype('float')\n",
    "df.insert(15, 'bathroom_number',df_bathrooms['bathroom_number'])\n",
    "df.insert(16, 'bathroom_type', df_bathrooms['bathroom_type'])\n",
    "del df['bathrooms_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6705188f-0607-439b-9898-e239313cb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter out price outliers\n",
    "df = df[(df.beds<10) & (df.price<750)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef94df2-03a6-4c1f-a16b-8f37ecc0d208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30580 entries, 0 to 42000\n",
      "Data columns (total 24 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   id                              30580 non-null  int64         \n",
      " 1   host_id                         30580 non-null  int64         \n",
      " 2   host_since                      30580 non-null  datetime64[ns]\n",
      " 3   host_location                   30580 non-null  object        \n",
      " 4   host_is_superhost               30580 non-null  object        \n",
      " 5   host_total_listings_count       30580 non-null  float64       \n",
      " 6   host_identity_verified          30580 non-null  object        \n",
      " 7   neighbourhood_cleansed          30580 non-null  object        \n",
      " 8   latitude                        30580 non-null  float64       \n",
      " 9   longitude                       30580 non-null  float64       \n",
      " 10  property_type                   30580 non-null  object        \n",
      " 11  room_type                       30580 non-null  object        \n",
      " 12  accommodates                    30580 non-null  int64         \n",
      " 13  bedrooms                        30580 non-null  float64       \n",
      " 14  bathroom_number                 30580 non-null  float64       \n",
      " 15  bathroom_type                   30580 non-null  object        \n",
      " 16  beds                            30580 non-null  float64       \n",
      " 17  amenities                       30580 non-null  object        \n",
      " 18  price                           30580 non-null  float64       \n",
      " 19  has_availability                30580 non-null  object        \n",
      " 20  number_of_reviews               30580 non-null  int64         \n",
      " 21  review_scores_rating            30580 non-null  float64       \n",
      " 22  instant_bookable                30580 non-null  object        \n",
      " 23  calculated_host_listings_count  30580 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(8), int64(5), object(10)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771a7727-4c2b-449d-acbb-ea88a5472662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[f    20236\n",
       " t    10344\n",
       " Name: host_is_superhost, dtype: int64,\n",
       " t    26080\n",
       " f     4500\n",
       " Name: host_identity_verified, dtype: int64,\n",
       " t    28785\n",
       " f     1795\n",
       " Name: has_availability, dtype: int64,\n",
       " f    19767\n",
       " t    10813\n",
       " Name: instant_bookable, dtype: int64]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.host_is_superhost.value_counts(),df.host_identity_verified.value_counts(),df.has_availability.value_counts(),df.instant_bookable.value_counts()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de56075-d76d-4607-a50a-9cedc07fe04b",
   "metadata": {},
   "source": [
    "# Create Models\n",
    "\n",
    "\n",
    "### Rubric Note: Create a logistic regression model and a support vecotr machine model for the classification task involved with your dataset. Assess how well each model performs (use a 80/20 train/test split for your data). Adjust parameters of the model to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. THat is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. FOr many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "843368e8-f02d-40f0-abca-06a0c57cd36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20236\n",
       "1    10344\n",
       "Name: host_is_superhost, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model will focus on classifying superhost status\n",
    "# since we're encoding with binary response, we can use labelencoder from sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['host_is_superhost'] = label_encoder.fit_transform(df['host_is_superhost'])\n",
    "df.host_is_superhost.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e211631-a474-45c2-bb8c-34bb9a4ea7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19767\n",
       "1    10813\n",
       "Name: instant_bookable, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode identity verified\n",
    "df['host_identity_verified'] = label_encoder.fit_transform(df['host_identity_verified'])\n",
    "df.host_identity_verified.value_counts()\n",
    "\n",
    "#encode has_availability\n",
    "df['has_availability'] = label_encoder.fit_transform(df['has_availability'])\n",
    "df.has_availability.value_counts()\n",
    "\n",
    "#encode instant bookable\n",
    "df['instant_bookable'] = label_encoder.fit_transform(df['instant_bookable'])\n",
    "df.instant_bookable.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ef38fe-7d74-4925-b8c8-63597a58be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## changing host_location to a binary feature of is_local using a list of LA area neighborhoods that will be used to extract from location str\n",
    "#los_angeles = pd.read_csv('Data_Files/LosAngelesNeighborhoods.csv')\n",
    "los_angeles = pd.read_csv('https://raw.githubusercontent.com/boneeyah/DS7331_Group/main/Data_Files/LosAngelesNeighborhoods.csv')\n",
    "los_angeles = los_angeles.iloc[:,0].tolist()\n",
    "\n",
    "pattern = '|'.join(los_angeles)\n",
    "df['host_is_local'] = df['host_location'].str.contains(pattern)\n",
    "\n",
    "df['host_is_local'] = label_encoder.fit_transform(df['host_is_local'])\n",
    "\n",
    "df = df.drop(columns= ['host_location']) #drop old host_location column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "169c40a7-445f-433e-b7c0-1f3c21a8353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30580 entries, 0 to 42000\n",
      "Data columns (total 24 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   id                              30580 non-null  int64         \n",
      " 1   host_id                         30580 non-null  int64         \n",
      " 2   host_since                      30580 non-null  datetime64[ns]\n",
      " 3   host_is_superhost               30580 non-null  int64         \n",
      " 4   host_total_listings_count       30580 non-null  float64       \n",
      " 5   host_identity_verified          30580 non-null  int64         \n",
      " 6   neighbourhood_cleansed          30580 non-null  object        \n",
      " 7   latitude                        30580 non-null  float64       \n",
      " 8   longitude                       30580 non-null  float64       \n",
      " 9   property_type                   30580 non-null  object        \n",
      " 10  room_type                       30580 non-null  object        \n",
      " 11  accommodates                    30580 non-null  int64         \n",
      " 12  bedrooms                        30580 non-null  float64       \n",
      " 13  bathroom_number                 30580 non-null  float64       \n",
      " 14  bathroom_type                   30580 non-null  object        \n",
      " 15  beds                            30580 non-null  float64       \n",
      " 16  amenities                       30580 non-null  object        \n",
      " 17  price                           30580 non-null  float64       \n",
      " 18  has_availability                30580 non-null  int64         \n",
      " 19  number_of_reviews               30580 non-null  int64         \n",
      " 20  review_scores_rating            30580 non-null  float64       \n",
      " 21  instant_bookable                30580 non-null  int64         \n",
      " 22  calculated_host_listings_count  30580 non-null  int64         \n",
      " 23  host_is_local                   30580 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(8), int64(10), object(5)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f1c92c-c941-4257-aab5-cf4528792798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding other categorical variables as a sparse dataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "df1 = df[['neighbourhood_cleansed','property_type', 'room_type', 'bathroom_type', 'amenities']] # to get only the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb4eeb-fea3-43f3-b4f2-238a5baa6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = make_column_transformer((OneHotEncoder(drop = 'first',sparse=False), ['neighbourhood_cleansed','property_type', 'room_type', 'bathroom_type', 'amenities']), remainder='passthrough')\n",
    "transformed = transformer.fit_transform(df1)\n",
    "transformed_df = pd.DataFrame(transformed, columns=transformer.get_feature_names_out())\n",
    "print(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb2bd741-57aa-41fa-a73d-0d8206f510dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['onehotencoder__neighbourhood_cleansed_Adams-Normandie',\n",
       "       'onehotencoder__neighbourhood_cleansed_Agoura Hills',\n",
       "       'onehotencoder__neighbourhood_cleansed_Agua Dulce', ...,\n",
       "       'onehotencoder__amenities_[\"Wifi\", \"Smoke alarm\", \"Long term stays allowed\", \"Kitchen\"]',\n",
       "       'onehotencoder__amenities_[\"Wifi\", \"Washer\", \"TV\", \"Kitchen\"]',\n",
       "       'onehotencoder__amenities_[]'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0017f-b9b2-43fd-bba7-b5420a7644ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.neighbourhood_cleansed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc384bc2-f380-4737-8fe3-3e2d5507e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.property_type.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bfe8a4-27e1-45a1-97d0-06231728a192",
   "metadata": {},
   "source": [
    "# Model Advantages\n",
    "\n",
    "### Rubric Note: Discuss the advantages of each model for each classifciation task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficience? Explain in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4d8aa-205d-49dc-89e4-13e7ec2b5df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f987ba70-eafc-4c48-820e-2a923b9ae43f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Interpret Feature Importance\n",
    "\n",
    "### Rubric Note: Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. WHy do you think some variables are more important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50919bda-d9b9-4d27-9aac-a71cab828ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45da7c16-ef28-4758-bebd-57e06dda4612",
   "metadata": {},
   "source": [
    "# Interpret Support Vectors\n",
    "\n",
    "### Rubric Note: Look at the chosen support vectors for the classfication task. Do these provide any 8insight into the data? Explain. IF you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model - then analyze the support vectors from the subsampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d008150-261a-4306-842b-d8ab51a68ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
