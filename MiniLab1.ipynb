{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c417ca4e-c052-44e2-9f4b-3e0c84e88cdc",
   "metadata": {},
   "source": [
    "#### data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722752c-e0e1-4862-bece-058690ae9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "df = pd.read_csv(\"https://media.githubusercontent.com/media/boneeyah/DS7331_Group/main/Data_Files/airbnb_los_angeles.csv\")\n",
    "#df = pd.read_csv(\"Data_Files/airbnb_los_angeles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8676f5-9c08-472a-94b0-7cf8ac42ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop variables which won't be useful for the classification model\n",
    "for col in [\n",
    "    'listing_url','scrape_id','last_scraped','description','neighborhood_overview','picture_url','host_url','host_about','host_response_time','host_response_rate','host_acceptance_rate',\n",
    "    'host_thumbnail_url','host_picture_url','host_verifications','host_has_profile_pic','bathroom_text','host_listings_count','host_neighbourhood','bathrooms','minimum_minimum_nights',\n",
    "    'maximum_minimum_nights','minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm','maximum_nights_avg_ntm','calendar_updated','availability_30','availability_60',\n",
    "    'availability_90','availability_365','calendar_last_scraped','number_of_reviews_ltm','number_of_reviews_l30d','review_scores_accuracy','review_scores_communication','review_scores_cleanliness',\n",
    "    'review_scores_checkin','review_scores_value','review_scores_location','calculated_host_listings_count_entire_homes','calculated_host_listings_count_private_rooms',\n",
    "    'calculated_host_listings_count_shared_rooms','reviews_per_month','neighbourhood','neighbourhood_group_cleansed', 'first_review','last_review','minimum_nights','maximum_nights','license','name','host_name','amenities'\n",
    "]:\n",
    "    if col in df:\n",
    "        del df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84031bd0-0813-4264-81fa-f3548cb72b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nulls\n",
    "df = df[~df.review_scores_rating.isnull() & ~df.bathrooms_text.isnull() & ~df.host_since.isnull() & ~df.host_location.isnull()]\n",
    "\n",
    "## getting property type from string\n",
    "types = ['Private room', 'Entire', 'Room in hotel','Room','Shared room']\n",
    "pat = '|'.join(r\"\\b{}\\b\".format(x) for x in types)\n",
    "\n",
    "df['property_type']= df['property_type'].str.extract('('+ pat + ')', expand = False)\n",
    "df['property_type'] = (df.property_type.\n",
    "                       fillna(value = 'other').\n",
    "                       replace(['Entire','Room in hotel'],['Entire unit','Hotel room']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58420e-ee3a-4444-a029-c8234aad0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute values based on median\n",
    "df['beds'] = df[['accommodates','beds']].groupby(by = 'accommodates').transform(lambda grp: grp.fillna(grp.median()))\n",
    "df_grouped = df.groupby(by = ['property_type','beds'])\n",
    "df_imputed = df_grouped[['beds','bedrooms']].transform(lambda grp: grp.fillna(grp.median()))\n",
    "\n",
    "index = df_imputed[df_imputed.bedrooms.isnull()].index\n",
    "df = df.drop(index= index)\n",
    "\n",
    "df['imputed']=df_imputed[['bedrooms']]\n",
    "\n",
    "# replace 'bedrooms' column with imputed column and deleting the duplicated column\n",
    "df['bedrooms'] = df['imputed']\n",
    "del df['imputed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e7586-90a1-4694-aa9f-54a8bdf0c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now fixing dtypes for attributes\n",
    "df['host_since'] = pd.to_datetime(df.host_since)\n",
    "df['price'] = df['price'].replace('[\\$,]','',regex = True).astype(float)\n",
    "df['bathrooms_text'] = df['bathrooms_text'].replace(['Half-bath', 'Shared half-bath', 'Private half-bath'],['0.5 bath','0.5 shared bath', '0.5 private bath'])\n",
    "df_bathrooms = df['bathrooms_text'].str.split(n=1, expand=True).rename(columns = {0:'bathroom_number',1:'bathroom_type'})\n",
    "df_bathrooms['bathroom_type'] = df_bathrooms.bathroom_type.fillna(value = 'bath')\n",
    "df_bathrooms['bathroom_type'] = df_bathrooms['bathroom_type'].replace(['baths','shared baths'],['bath','shared bath'])\n",
    "df_bathrooms['bathroom_number'] = df_bathrooms['bathroom_number'].astype('float')\n",
    "df.insert(15, 'bathroom_number',df_bathrooms['bathroom_number'])\n",
    "df.insert(16, 'bathroom_type', df_bathrooms['bathroom_type'])\n",
    "del df['bathrooms_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705188f-0607-439b-9898-e239313cb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter out price outliers\n",
    "df = df[(df.beds<10) & (df.price<750)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef94df2-03a6-4c1f-a16b-8f37ecc0d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a7727-4c2b-449d-acbb-ea88a5472662",
   "metadata": {},
   "outputs": [],
   "source": [
    "[df.host_is_superhost.value_counts(),df.host_identity_verified.value_counts(),df.has_availability.value_counts(),df.instant_bookable.value_counts()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de56075-d76d-4607-a50a-9cedc07fe04b",
   "metadata": {},
   "source": [
    "# Create Models\n",
    "\n",
    "\n",
    "### Rubric Note: Create a logistic regression model and a support vecotr machine model for the classification task involved with your dataset. Assess how well each model performs (use a 80/20 train/test split for your data). Adjust parameters of the model to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. THat is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. FOr many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843368e8-f02d-40f0-abca-06a0c57cd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model will focus on classifying superhost status\n",
    "# since we're encoding with binary response, we can use labelencoder from sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['host_is_superhost'] = label_encoder.fit_transform(df['host_is_superhost'])\n",
    "df.host_is_superhost.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e211631-a474-45c2-bb8c-34bb9a4ea7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## encoding binary categorical variables\n",
    "# encode identity verified\n",
    "df['host_identity_verified'] = label_encoder.fit_transform(df['host_identity_verified'])\n",
    "df.host_identity_verified.value_counts()\n",
    "\n",
    "#encode has_availability\n",
    "df['has_availability'] = label_encoder.fit_transform(df['has_availability'])\n",
    "df.has_availability.value_counts()\n",
    "\n",
    "#encode instant bookable\n",
    "df['instant_bookable'] = label_encoder.fit_transform(df['instant_bookable'])\n",
    "df.instant_bookable.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef38fe-7d74-4925-b8c8-63597a58be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## changing host_location to a binary feature of is_local using a list of LA area neighborhoods that will be used to extract from location str\n",
    "#los_angeles = pd.read_csv('Data_Files/LosAngelesNeighborhoods.csv')\n",
    "los_angeles = pd.read_csv('https://raw.githubusercontent.com/boneeyah/DS7331_Group/main/Data_Files/LosAngelesNeighborhoods.csv')\n",
    "los_angeles = los_angeles.iloc[:,0].tolist()\n",
    "\n",
    "pattern = '|'.join(los_angeles)\n",
    "df['host_is_local'] = df['host_location'].str.contains(pattern)\n",
    "\n",
    "df['host_is_local'] = label_encoder.fit_transform(df['host_is_local'])\n",
    "\n",
    "df = df.drop(columns= ['host_location']) #drop old host_location column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c40a7-445f-433e-b7c0-1f3c21a8353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1c92c-c941-4257-aab5-cf4528792798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding other categorical variables as a non-sparse dataframe\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "df_temp = df[['neighbourhood_cleansed','property_type', 'room_type', 'bathroom_type']] # to get only the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c799bcac-826c-4c0b-be36-f697cf28c385",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop='first',sparse=False)\n",
    "feature_arr = ohe.fit_transform(df_temp[['neighbourhood_cleansed','property_type', 'room_type', 'bathroom_type']])\n",
    "feature_labels = ohe.get_feature_names_out()\n",
    "\n",
    "#create dataframe with features\n",
    "pd.DataFrame(feature_arr, columns= feature_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f7057-31f5-4764-ace1-9be2f11e6b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec75e9-070e-450a-9a28-11a916f1ff8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb4eeb-fea3-43f3-b4f2-238a5baa6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### different method I found first, commented out for now, this could be used to transform within the original dataset saving one step\n",
    "### but it's easy enough to just fit a new dataframe and then add to original and drop original columns instead\n",
    "#transformer = make_column_transformer((OneHotEncoder(drop = 'first',sparse=False), ['neighbourhood_cleansed','property_type', 'room_type', 'bathroom_type']), remainder='passthrough')\n",
    "#df_temp = transformer.fit_transform(df_temp)\n",
    "#df_temp = pd.DataFrame(df_temp, columns=transformer.get_feature_names_out())\n",
    "#print(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83169115-f751-4728-b3ae-15cda28cbd36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0017f-b9b2-43fd-bba7-b5420a7644ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc384bc2-f380-4737-8fe3-3e2d5507e18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15bfe8a4-27e1-45a1-97d0-06231728a192",
   "metadata": {},
   "source": [
    "# Model Advantages\n",
    "\n",
    "### Rubric Note: Discuss the advantages of each model for each classifciation task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficience? Explain in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4d8aa-205d-49dc-89e4-13e7ec2b5df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f987ba70-eafc-4c48-820e-2a923b9ae43f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Interpret Feature Importance\n",
    "\n",
    "### Rubric Note: Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. WHy do you think some variables are more important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50919bda-d9b9-4d27-9aac-a71cab828ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45da7c16-ef28-4758-bebd-57e06dda4612",
   "metadata": {},
   "source": [
    "# Interpret Support Vectors\n",
    "\n",
    "### Rubric Note: Look at the chosen support vectors for the classfication task. Do these provide any 8insight into the data? Explain. IF you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model - then analyze the support vectors from the subsampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d008150-261a-4306-842b-d8ab51a68ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
