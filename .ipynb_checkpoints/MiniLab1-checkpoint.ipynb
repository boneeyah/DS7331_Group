{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c417ca4e-c052-44e2-9f4b-3e0c84e88cdc",
   "metadata": {},
   "source": [
    "#### data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9722752c-e0e1-4862-bece-058690ae9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "df = pd.read_csv(\"https://media.githubusercontent.com/media/boneeyah/DS7331_Group/main/Data_Files/airbnb_los_angeles.csv\")\n",
    "#df = pd.read_csv(\"Data_Files/airbnb_los_angeles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8676f5-9c08-472a-94b0-7cf8ac42ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop variables which won't be useful for the classification model\n",
    "for col in [\n",
    "    'listing_url','scrape_id','last_scraped','description','neighborhood_overview','picture_url','host_url','host_about','host_response_time','host_response_rate','host_acceptance_rate',\n",
    "    'host_thumbnail_url','host_picture_url','host_verifications','host_has_profile_pic','bathroom_text','host_listings_count','host_neighbourhood','bathrooms','minimum_minimum_nights',\n",
    "    'maximum_minimum_nights','minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm','maximum_nights_avg_ntm','calendar_updated','availability_30','availability_60',\n",
    "    'availability_90','availability_365','calendar_last_scraped','number_of_reviews_ltm','number_of_reviews_l30d','review_scores_accuracy','review_scores_communication','review_scores_cleanliness',\n",
    "    'review_scores_checkin','review_scores_value','review_scores_location','calculated_host_listings_count_entire_homes','calculated_host_listings_count_private_rooms',\n",
    "    'calculated_host_listings_count_shared_rooms','reviews_per_month','neighbourhood','neighbourhood_group_cleansed', 'first_review','last_review','minimum_nights','maximum_nights','license'\n",
    "]:\n",
    "    if col in df:\n",
    "        del df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84031bd0-0813-4264-81fa-f3548cb72b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entire unit     22767\n",
       "Private room     8081\n",
       "Shared room       510\n",
       "Room              401\n",
       "other             298\n",
       "Hotel room        272\n",
       "Name: property_type, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove nulls\n",
    "df = df[~df.review_scores_rating.isnull() & ~df.bathrooms_text.isnull() & ~df.host_since.isnull() & ~df.host_location.isnull()]\n",
    "\n",
    "## getting property type from string\n",
    "types = ['Private room', 'Entire', 'Room in hotel','Room','Shared room']\n",
    "pat = '|'.join(r\"\\b{}\\b\".format(x) for x in types)\n",
    "\n",
    "df['property_type']= df['property_type'].str.extract('('+ pat + ')', expand = False)\n",
    "df['property_type'] = (df.property_type.\n",
    "                       fillna(value = 'other').\n",
    "                       replace(['Entire','Room in hotel'],['Entire unit','Hotel room']))\n",
    "df['property_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e58420e-ee3a-4444-a029-c8234aad0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute values based on median\n",
    "df['beds'] = df[['accommodates','beds']].groupby(by = 'accommodates').transform(lambda grp: grp.fillna(grp.median()))\n",
    "df_grouped = df.groupby(by = ['property_type','beds'])\n",
    "df_imputed = df_grouped[['beds','bedrooms']].transform(lambda grp: grp.fillna(grp.median()))\n",
    "\n",
    "index = df_imputed[df_imputed.bedrooms.isnull()].index\n",
    "df = df.drop(index= index)\n",
    "\n",
    "df['imputed']=df_imputed[['bedrooms']]\n",
    "\n",
    "# replace 'bedrooms' column with imputed column and deleting the duplicated column\n",
    "df['bedrooms'] = df['imputed']\n",
    "del df['imputed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63e7586-90a1-4694-aa9f-54a8bdf0c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now fixing dtypes for attributes\n",
    "df['host_since'] = pd.to_datetime(df.host_since)\n",
    "df['price'] = df['price'].replace('[\\$,]','',regex = True).astype(float)\n",
    "df['bathrooms_text'] = df['bathrooms_text'].replace(['Half-bath', 'Shared half-bath', 'Private half-bath'],['0.5 bath','0.5 shared bath', '0.5 private bath'])\n",
    "df_bathrooms = df['bathrooms_text'].str.split(n=1, expand=True).rename(columns = {0:'bathroom_number',1:'bathroom_type'})\n",
    "df_bathrooms['bathroom_type'] = df_bathrooms.bathroom_type.fillna(value = 'bath')\n",
    "df_bathrooms['bathroom_type'] = df_bathrooms['bathroom_type'].replace(['baths','shared baths'],['bath','shared bath'])\n",
    "df_bathrooms['bathroom_number'] = df_bathrooms['bathroom_number'].astype('float')\n",
    "df.insert(15, 'bathroom_number',df_bathrooms['bathroom_number'])\n",
    "df.insert(16, 'bathroom_type', df_bathrooms['bathroom_type'])\n",
    "del df['bathrooms_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6705188f-0607-439b-9898-e239313cb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter out price outliers\n",
    "df = df[(df.beds<10) & (df.price<750)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef94df2-03a6-4c1f-a16b-8f37ecc0d208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30580 entries, 0 to 30579\n",
      "Data columns (total 26 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   id                              30580 non-null  int64         \n",
      " 1   name                            30580 non-null  object        \n",
      " 2   host_id                         30580 non-null  int64         \n",
      " 3   host_name                       30580 non-null  object        \n",
      " 4   host_since                      30580 non-null  datetime64[ns]\n",
      " 5   host_location                   30580 non-null  object        \n",
      " 6   host_is_superhost               30580 non-null  object        \n",
      " 7   host_total_listings_count       30580 non-null  float64       \n",
      " 8   host_identity_verified          30580 non-null  object        \n",
      " 9   neighbourhood_cleansed          30580 non-null  object        \n",
      " 10  latitude                        30580 non-null  float64       \n",
      " 11  longitude                       30580 non-null  float64       \n",
      " 12  property_type                   30580 non-null  object        \n",
      " 13  room_type                       30580 non-null  object        \n",
      " 14  accommodates                    30580 non-null  int64         \n",
      " 15  bathroom_number                 30580 non-null  float64       \n",
      " 16  bathroom_type                   30580 non-null  object        \n",
      " 17  bedrooms                        30580 non-null  float64       \n",
      " 18  beds                            30580 non-null  float64       \n",
      " 19  amenities                       30580 non-null  object        \n",
      " 20  price                           30580 non-null  float64       \n",
      " 21  has_availability                30580 non-null  object        \n",
      " 22  number_of_reviews               30580 non-null  int64         \n",
      " 23  review_scores_rating            30580 non-null  float64       \n",
      " 24  instant_bookable                30580 non-null  object        \n",
      " 25  calculated_host_listings_count  30580 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(8), int64(5), object(12)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de56075-d76d-4607-a50a-9cedc07fe04b",
   "metadata": {},
   "source": [
    "# Create Models\n",
    "\n",
    "\n",
    "### Rubric Note: Create a logistic regression model and a support vecotr machine model for the classification task involved with your dataset. Assess how well each model performs (use a 80/20 train/test split for your data). Adjust parameters of the model to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. THat is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. FOr many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "843368e8-f02d-40f0-abca-06a0c57cd36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20236\n",
       "1    10344\n",
       "Name: host_is_superhost, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model will focus on classifying superhost status\n",
    "# since we're encoding with binary response, we can use labelencoder from sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['host_is_superhost'] = label_encoder.fit_transform(df['host_is_superhost'])\n",
    "df.host_is_superhost.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e211631-a474-45c2-bb8c-34bb9a4ea7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19767\n",
       "1    10813\n",
       "Name: instant_bookable, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## encoding binary categorical variables\n",
    "# encode identity verified\n",
    "df['host_identity_verified'] = label_encoder.fit_transform(df['host_identity_verified'])\n",
    "df.host_identity_verified.value_counts()\n",
    "\n",
    "#encode has_availability\n",
    "df['has_availability'] = label_encoder.fit_transform(df['has_availability'])\n",
    "df.has_availability.value_counts()\n",
    "\n",
    "#encode instant bookable\n",
    "df['instant_bookable'] = label_encoder.fit_transform(df['instant_bookable'])\n",
    "df.instant_bookable.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38ef38fe-7d74-4925-b8c8-63597a58be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## changing host_location to a binary feature of is_local using a list of LA area neighborhoods that will be used to extract from location str\n",
    "#los_angeles = pd.read_csv('Data_Files/LosAngelesNeighborhoods.csv')\n",
    "los_angeles = pd.read_csv('https://raw.githubusercontent.com/boneeyah/DS7331_Group/main/Data_Files/LosAngelesNeighborhoods.csv')\n",
    "los_angeles = los_angeles.iloc[:,0].tolist()\n",
    "\n",
    "pattern = '|'.join(los_angeles)\n",
    "df['host_is_local'] = df['host_location'].str.contains(pattern)\n",
    "\n",
    "df['host_is_local'] = label_encoder.fit_transform(df['host_is_local'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7be9bb4-5b2e-4ef2-a251-c4d88f1dd246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30580 entries, 0 to 30579\n",
      "Data columns (total 26 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              30580 non-null  int64  \n",
      " 1   name                            30580 non-null  object \n",
      " 2   host_id                         30580 non-null  int64  \n",
      " 3   host_name                       30580 non-null  object \n",
      " 4   host_is_superhost               30580 non-null  int64  \n",
      " 5   host_total_listings_count       30580 non-null  float64\n",
      " 6   host_identity_verified          30580 non-null  int64  \n",
      " 7   neighbourhood_cleansed          30580 non-null  object \n",
      " 8   latitude                        30580 non-null  float64\n",
      " 9   longitude                       30580 non-null  float64\n",
      " 10  property_type                   30580 non-null  object \n",
      " 11  room_type                       30580 non-null  object \n",
      " 12  accommodates                    30580 non-null  int64  \n",
      " 13  bathroom_number                 30580 non-null  float64\n",
      " 14  bathroom_type                   30580 non-null  object \n",
      " 15  bedrooms                        30580 non-null  float64\n",
      " 16  beds                            30580 non-null  float64\n",
      " 17  amenities                       30580 non-null  object \n",
      " 18  price                           30580 non-null  float64\n",
      " 19  has_availability                30580 non-null  int64  \n",
      " 20  number_of_reviews               30580 non-null  int64  \n",
      " 21  review_scores_rating            30580 non-null  float64\n",
      " 22  instant_bookable                30580 non-null  int64  \n",
      " 23  calculated_host_listings_count  30580 non-null  int64  \n",
      " 24  host_is_local                   30580 non-null  int64  \n",
      " 25  host_for                        30580 non-null  float64\n",
      "dtypes: float64(9), int64(10), object(7)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "## changing host_since to host_for to get a a numerical variable that corresponds to length in months\n",
    "## data is from June 6 2022, 06-06-2022\n",
    "end_date = pd.to_datetime('06-06-2022', format= \"%m-%d-%Y\")\n",
    "df['host_for'] = (end_date-df.host_since)/np.timedelta64(1,'M')\n",
    "\n",
    "df = df.drop(columns= ['host_location', 'host_since']) #drop old host_location and host_since columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70f1c92c-c941-4257-aab5-cf4528792798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding other categorical variables as a non-sparse dataframe\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "df_temp = df[['id','neighbourhood_cleansed','property_type', 'room_type', 'bathroom_type']] # to get only the cat variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c799bcac-826c-4c0b-be36-f697cf28c385",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop='first',sparse=False)\n",
    "feature_arr = ohe.fit_transform(df_temp[['neighbourhood_cleansed','property_type', 'room_type', 'bathroom_type']])\n",
    "feature_labels = ohe.get_feature_names_out()\n",
    "\n",
    "#create dataframe with features\n",
    "df_temp = pd.DataFrame(feature_arr, columns= feature_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eec75e9-070e-450a-9a28-11a916f1ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original columns and join with new onehotencoded columns\n",
    "df = df.drop(columns = ['neighbourhood_cleansed','property_type', 'room_type', 'bathroom_type','amenities','name','host_name','id','host_id']).join(df_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cefb4eeb-fea3-43f3-b4f2-238a5baa6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### different method I found first, commented out for now, this could be used to transform within the original dataset saving one step\n",
    "### but it's easy enough to just fit a new dataframe and then add to original and drop original columns instead\n",
    "#transformer = make_column_transformer((OneHotEncoder(drop = 'first',sparse=False), ['neighbourhood_cleansed','property_type', 'room_type', 'bathroom_type']), remainder='passthrough')\n",
    "#df_temp = transformer.fit_transform(df_temp)\n",
    "#df_temp = pd.DataFrame(df_temp, columns=transformer.get_feature_names_out())\n",
    "#print(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7387da7-ff79-4f7c-98d9-56b7b97a8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### clean up temporary files\n",
    "del df_temp, feature_arr, feature_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83169115-f751-4728-b3ae-15cda28cbd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30580 entries, 0 to 30579\n",
      "Columns: 328 entries, host_is_superhost to bathroom_type_shared bath\n",
      "dtypes: float64(320), int64(8)\n",
      "memory usage: 76.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1c0017f-b9b2-43fd-bba7-b5420a7644ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### performing 80/20 split using sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "seed = 1002 #seed to be used, it will be assigned as random_state when splitting instead of using np to set seed\n",
    "#dividing dataset into features and labels\n",
    "X = df.loc[:,df.columns != 'host_is_superhost']\n",
    "X_sc = StandardScaler().fit_transform(X)\n",
    "y = df.loc[:, df.columns == 'host_is_superhost']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sc,y, random_state=seed, train_size=.8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc384bc2-f380-4737-8fe3-3e2d5507e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lor_clf = LogisticRegressionCV(cv=10, max_iter = 1000, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d95a153-c13b-4ffe-8ac4-e3b1b328a4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=10, max_iter=1000, random_state=1002)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=10, max_iter=1000, random_state=1002)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(cv=10, max_iter=1000, random_state=1002)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lor_clf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f190e10-053c-46be-8fd5-e2d61fe69bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15bfe8a4-27e1-45a1-97d0-06231728a192",
   "metadata": {},
   "source": [
    "# Model Advantages\n",
    "\n",
    "### Rubric Note: Discuss the advantages of each model for each classifciation task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficience? Explain in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4d8aa-205d-49dc-89e4-13e7ec2b5df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f987ba70-eafc-4c48-820e-2a923b9ae43f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Interpret Feature Importance\n",
    "\n",
    "### Rubric Note: Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. WHy do you think some variables are more important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50919bda-d9b9-4d27-9aac-a71cab828ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45da7c16-ef28-4758-bebd-57e06dda4612",
   "metadata": {},
   "source": [
    "# Interpret Support Vectors\n",
    "\n",
    "### Rubric Note: Look at the chosen support vectors for the classfication task. Do these provide any 8insight into the data? Explain. IF you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model - then analyze the support vectors from the subsampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d008150-261a-4306-842b-d8ab51a68ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
